{
  "name": "openai-ollama-local-proxy",
  "version": "1.0.0",
  "description": "A proxy server that redirects OpenAI API requests to a local Ollama instance",
  "main": "src/index.js",
  "type": "module",
  "scripts": {
    "start": "node src/index.js",
    "dev": "nodemon src/index.js",
    "test": "jest",
    "lint": "eslint . --ext .js,.mjs && prettier --check ."
  },
  "keywords": [
    "openai",
    "ollama",
    "proxy",
    "api",
    "llm"
  ],
  "author": "",
  "license": "MIT",
  "dependencies": {
    "axios": "^1.6.2",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "morgan": "^1.10.0",
    "node-mocks-http": "^1.17.2"
  },
  "devDependencies": {
    "eslint": "^8.0.0",
    "prettier": "^3.0.0",
    "jest": "^29.0.0",
    "nodemon": "^3.0.1",
    "supertest": "^6.0.0"
  }
}
